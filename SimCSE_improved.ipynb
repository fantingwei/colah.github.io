{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "accelerator": "TPU",
    "colab": {
      "name": "SimCSE-improved.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "mount_file_id": "1tar6oF4C2_6YtEaYAikyotjaWrmyt4Yp",
      "authorship_tag": "ABX9TyN/omo6bztr5LeqrYRIcWkE",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/fantingwei/colah.github.io/blob/master/SimCSE_improved.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4tt5pzdAM3Cf",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "64a6a149-e65f-418e-b6f3-cec7659f830f"
      },
      "source": [
        "!sudo lsb_release -a"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "No LSB modules are available.\n",
            "Distributor ID:\tUbuntu\n",
            "Description:\tUbuntu 18.04.5 LTS\n",
            "Release:\t18.04\n",
            "Codename:\tbionic\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "y66RDO7Q-dyh",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "4cc8a8c6-5d85-4f0e-8c0c-84b8031548d9"
      },
      "source": [
        "# Load the Drive helper and mount\n",
        "from google.colab import drive\n",
        " \n",
        "# This will prompt for authorization.\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DBp2DfFNSQFq",
        "outputId": "10f24bc2-f75f-4131-bb0a-932a6bfcaf64"
      },
      "source": [
        "!pip install torch==1.7.1+cu110 -f https://download.pytorch.org/whl/torch_stable.html"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in links: https://download.pytorch.org/whl/torch_stable.html\n",
            "Requirement already satisfied: torch==1.7.1+cu110 in /usr/local/lib/python3.7/dist-packages (1.7.1+cu110)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from torch==1.7.1+cu110) (1.21.5)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.7/dist-packages (from torch==1.7.1+cu110) (3.10.0.2)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ORVm4BDpXBm4",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "033cb510-181a-4704-f346-67e38f518ad4"
      },
      "source": [
        "!git clone https://github.com/princeton-nlp/SimCSE"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'SimCSE'...\n",
            "remote: Enumerating objects: 393, done.\u001b[K\n",
            "remote: Counting objects: 100% (106/106), done.\u001b[K\n",
            "remote: Compressing objects: 100% (71/71), done.\u001b[K\n",
            "remote: Total 393 (delta 54), reused 41 (delta 34), pack-reused 287\u001b[K\n",
            "Receiving objects: 100% (393/393), 41.45 MiB | 31.89 MiB/s, done.\n",
            "Resolving deltas: 100% (197/197), done.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip uninstall tensorflow\n",
        "!pip uninstall fastai\n",
        "!pip uninstall yellowbrick\n",
        "!pip uninstall datascience \n",
        "!pip uninstall albumentations"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Lvt-WU7CYZ0m",
        "outputId": "197c654d-6631-4fff-8e67-ac2f72ff1c8c"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found existing installation: tensorflow 2.8.0\n",
            "Uninstalling tensorflow-2.8.0:\n",
            "  Would remove:\n",
            "    /usr/local/bin/estimator_ckpt_converter\n",
            "    /usr/local/bin/import_pb_to_tensorboard\n",
            "    /usr/local/bin/saved_model_cli\n",
            "    /usr/local/bin/tensorboard\n",
            "    /usr/local/bin/tf_upgrade_v2\n",
            "    /usr/local/bin/tflite_convert\n",
            "    /usr/local/bin/toco\n",
            "    /usr/local/bin/toco_from_protos\n",
            "    /usr/local/lib/python3.7/dist-packages/tensorflow-2.8.0.dist-info/*\n",
            "    /usr/local/lib/python3.7/dist-packages/tensorflow/*\n",
            "Proceed (y/n)? \u001b[31mERROR: Operation cancelled by user\u001b[0m\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/pip/_internal/cli/base_command.py\", line 180, in _main\n",
            "    status = self.run(options, args)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/pip/_internal/commands/uninstall.py\", line 86, in run\n",
            "    auto_confirm=options.yes, verbose=self.verbosity > 0,\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/pip/_internal/req/req_install.py\", line 658, in uninstall\n",
            "    uninstalled_pathset.remove(auto_confirm, verbose)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/pip/_internal/req/req_uninstall.py\", line 380, in remove\n",
            "    if auto_confirm or self._allowed_to_proceed(verbose):\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/pip/_internal/req/req_uninstall.py\", line 423, in _allowed_to_proceed\n",
            "    return ask('Proceed (y/n)? ', ('y', 'n')) == 'y'\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/pip/_internal/utils/misc.py\", line 203, in ask\n",
            "    response = input(message)\n",
            "KeyboardInterrupt\n",
            "\n",
            "During handling of the above exception, another exception occurred:\n",
            "\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/bin/pip3\", line 8, in <module>\n",
            "    sys.exit(main())\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/pip/_internal/cli/main.py\", line 71, in main\n",
            "    return command.main(cmd_args)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/pip/_internal/cli/base_command.py\", line 104, in main\n",
            "    return self._main(args)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/pip/_internal/cli/base_command.py\", line 213, in _main\n",
            "    logger.debug(\"Exception information:\", exc_info=True)\n",
            "  File \"/usr/lib/python3.7/logging/__init__.py\", line 1366, in debug\n",
            "    self._log(DEBUG, msg, args, **kwargs)\n",
            "  File \"/usr/lib/python3.7/logging/__init__.py\", line 1514, in _log\n",
            "    self.handle(record)\n",
            "  File \"/usr/lib/python3.7/logging/__init__.py\", line 1524, in handle\n",
            "    self.callHandlers(record)\n",
            "  File \"/usr/lib/python3.7/logging/__init__.py\", line 1586, in callHandlers\n",
            "    hdlr.handle(record)\n",
            "  File \"/usr/lib/python3.7/logging/__init__.py\", line 894, in handle\n",
            "    self.emit(record)\n",
            "  File \"/usr/lib/python3.7/logging/handlers.py\", line 71, in emit\n",
            "    logging.FileHandler.emit(self, record)\n",
            "  File \"/usr/lib/python3.7/logging/__init__.py\", line 1127, in emit\n",
            "    StreamHandler.emit(self, record)\n",
            "  File \"/usr/lib/python3.7/logging/__init__.py\", line 1025, in emit\n",
            "    msg = self.format(record)\n",
            "  File \"/usr/lib/python3.7/logging/__init__.py\", line 869, in format\n",
            "    return fmt.format(record)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/pip/_internal/utils/logging.py\", line 130, in format\n",
            "    formatted = super().format(record)\n",
            "  File \"/usr/lib/python3.7/logging/__init__.py\", line 616, in format\n",
            "    record.exc_text = self.formatException(record.exc_info)\n",
            "  File \"/usr/lib/python3.7/logging/__init__.py\", line 566, in formatException\n",
            "    traceback.print_exception(ei[0], ei[1], tb, None, sio)\n",
            "  File \"/usr/lib/python3.7/traceback.py\", line 104, in print_exception\n",
            "    type(value), value, tb, limit=limit).format(chain=chain):\n",
            "  File \"/usr/lib/python3.7/traceback.py\", line 508, in __init__\n",
            "    capture_locals=capture_locals)\n",
            "  File \"/usr/lib/python3.7/traceback.py\", line 363, in extract\n",
            "    f.line\n",
            "  File \"/usr/lib/python3.7/traceback.py\", line 285, in line\n",
            "    self._line = linecache.getline(self.filename, self.lineno).strip()\n",
            "  File \"/usr/lib/python3.7/linecache.py\", line 16, in getline\n",
            "    lines = getlines(filename, module_globals)\n",
            "  File \"/usr/lib/python3.7/linecache.py\", line 47, in getlines\n",
            "    return updatecache(filename, module_globals)\n",
            "  File \"/usr/lib/python3.7/linecache.py\", line 136, in updatecache\n",
            "    with tokenize.open(fullname) as fp:\n",
            "KeyboardInterrupt\n",
            "Found existing installation: fastai 1.0.61\n",
            "Uninstalling fastai-1.0.61:\n",
            "  Would remove:\n",
            "    /usr/local/lib/python3.7/dist-packages/fastai-1.0.61.dist-info/*\n",
            "    /usr/local/lib/python3.7/dist-packages/fastai/*\n",
            "Proceed (y/n)? y\n",
            "  Successfully uninstalled fastai-1.0.61\n",
            "Found existing installation: yellowbrick 1.4\n",
            "Uninstalling yellowbrick-1.4:\n",
            "  Would remove:\n",
            "    /usr/local/lib/python3.7/dist-packages/yellowbrick-1.4.dist-info/*\n",
            "    /usr/local/lib/python3.7/dist-packages/yellowbrick/*\n",
            "Proceed (y/n)? y\n",
            "  Successfully uninstalled yellowbrick-1.4\n",
            "Found existing installation: datascience 0.10.6\n",
            "Uninstalling datascience-0.10.6:\n",
            "  Would remove:\n",
            "    /usr/local/lib/python3.7/dist-packages/datascience-0.10.6.dist-info/*\n",
            "    /usr/local/lib/python3.7/dist-packages/datascience/*\n",
            "Proceed (y/n)? y\n",
            "  Successfully uninstalled datascience-0.10.6\n",
            "Found existing installation: albumentations 0.1.12\n",
            "Uninstalling albumentations-0.1.12:\n",
            "  Would remove:\n",
            "    /usr/local/lib/python3.7/dist-packages/albumentations-0.1.12.dist-info/*\n",
            "    /usr/local/lib/python3.7/dist-packages/albumentations/*\n",
            "Proceed (y/n)? y\n",
            "  Successfully uninstalled albumentations-0.1.12\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sWyrQwZsFu12"
      },
      "source": [
        "%cd /content/SimCSE/SentEval/data/downstream/\n",
        "!bash download_dataset.sh"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uBjEKZcpXpdR"
      },
      "source": [
        "!pip list"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tmcZGw7PMlMw"
      },
      "source": [
        "# %cd /content/SimCSE/\n",
        "# !python train.py --help"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "r6mlw3df7sKv"
      },
      "source": [
        "#change lines in evaluation Then go on\n",
        "# Set PATHs\n",
        "PATH_TO_SENTEVAL = '/content/SimCSE/SentEval'\\\n",
        "PATH_TO_DATA = '/content/SimCSE/SentEval/data'\n",
        "#line84\n",
        "import SentEval\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "agvLtRgYzx49"
      },
      "source": [
        "# !python /content/SimCSE/evaluation.py \\\n",
        "#     --model_name_or_path princeton-nlp/unsup-simcse-bert-base-uncased \\\n",
        "#     --pooler cls \\\n",
        "#     --task_set sts \\\n",
        "#     --mode test"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZdhvE0BpZBc0"
      },
      "source": [
        "# Train Unsupervised SimCSE"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BlacBt1ENlT8"
      },
      "source": [
        "##Other Modification:\n",
        "/content/SimCSE/train.py\n",
        "/content/wiki1m_for_simcse.txt\n",
        "/content/my-unsup-simcse-bert-base-uncased"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iIyIAtDEZNog"
      },
      "source": [
        "%cd /content/SimCSE/\n",
        "!bash /content/SimCSE/data/download_wiki.sh"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1HaRLGyH6xxP"
      },
      "source": [
        "# !pip uninstall apex"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "I6QR9wQLuzDD"
      },
      "source": [
        "#通过sh训练"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2P7EfJY3VeCv",
        "outputId": "465aacc5-60ae-43c2-beb9-417f28ce66ad"
      },
      "source": [
        "!bash /content/SimCSE/run_unsup_example.sh"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "  0% 33/15626 [20:30<160:37:27, 37.08s/it]"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "As_Wm_5ZfLep"
      },
      "source": [
        "!cuda --version"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "q4QamoRVu5x5"
      },
      "source": [
        "#通过train.py训练\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "81eW0F2W-_P1"
      },
      "source": [
        "%cd /content/SimCSE/\n",
        "!bash /content/SimCSE/data/download_wiki.sh"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "background_save": true,
          "base_uri": "https://localhost:8080/"
        },
        "id": "UEvPzGBcTqYL",
        "outputId": "335dfc88-4188-40b0-ebe0-131e2be13c86"
      },
      "source": [
        "!python train.py --model_name_or_path=bert-base-uncased --train_file=wiki1m_for_simcse.txt --output_dir=SimCSE/result/my-unsup-simcse-bert-base-uncased --num_train_epochs=1 --per_device_train_batch_size=64 --learning_rate=3e-5 --max_seq_length=32 --evaluation_strategy=steps --metric_for_best_model=stsb_spearman --load_best_model_at_end --eval_steps=125 --pooler_type=cls_before_pooler --overwrite_output_dir --do_train --do_eval"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "2021-06-11 07:32:06.960318: I tensorflow/stream_executor/platform/default/dso_loader.cc:53] Successfully opened dynamic library libcudart.so.11.0\n",
            "06/11/2021 07:32:08 - INFO - __main__ -   PyTorch: setting up devices\n",
            "ModelArguments(model_name_or_path='princeton-nlp/unsup-simcse-bert-base-uncased', model_type=None, config_name=None, tokenizer_name=None, cache_dir=None, use_fast_tokenizer=True, model_revision='main', use_auth_token=False, temp=0.05, pooler_type='cls_before_pooler', hard_negative_weight=0, do_mlm=False, mlm_weight=0.1, align_w=0.2, unif_w=0.1, mlp_only_train=False) \n",
            "\n",
            "DataTrainingArguments(dataset_name=None, dataset_config_name=None, overwrite_cache=False, validation_split_percentage=5, preprocessing_num_workers=None, train_file='/content/SimCSE/wiki1m_for_simcse.txt', max_seq_length=32, pad_to_max_length=False, mlm_probability=0.15) \n",
            "\n",
            "OurTrainingArguments(output_dir='SimCSE/result/my-unsup-simcse-bert-base-uncased', overwrite_output_dir=True, do_train=True, do_eval=True, do_predict=False, evaluation_strategy=<EvaluationStrategy.STEPS: 'steps'>, prediction_loss_only=False, per_device_train_batch_size=64, per_device_eval_batch_size=8, per_gpu_train_batch_size=None, per_gpu_eval_batch_size=None, gradient_accumulation_steps=1, eval_accumulation_steps=None, learning_rate=3e-05, weight_decay=0.0, adam_beta1=0.9, adam_beta2=0.999, adam_epsilon=1e-08, max_grad_norm=1.0, num_train_epochs=1.0, max_steps=-1, lr_scheduler_type=<SchedulerType.LINEAR: 'linear'>, warmup_steps=0, logging_dir='runs/Jun11_07-32-08_b24871aa421a', logging_first_step=False, logging_steps=500, save_steps=500, save_total_limit=None, no_cuda=False, seed=42, fp16=False, fp16_opt_level='O1', fp16_backend='auto', local_rank=-1, tpu_num_cores=None, tpu_metrics_debug=False, debug=False, dataloader_drop_last=False, eval_steps=125, dataloader_num_workers=0, past_index=-1, run_name='SimCSE/result/my-unsup-simcse-bert-base-uncased', disable_tqdm=False, remove_unused_columns=True, label_names=None, load_best_model_at_end=True, metric_for_best_model='stsb_spearman', greater_is_better=True, ignore_data_skip=False, sharded_ddp=False, deepspeed=None, label_smoothing_factor=0.0, adafactor=False, eval_transfer=False) \n",
            "\n",
            "06/11/2021 07:32:08 - WARNING - __main__ -   Process rank: -1, device: cpu, n_gpu: 0 distributed training: False, 16-bits training: False\n",
            "06/11/2021 07:32:08 - INFO - __main__ -   Training/evaluation parameters OurTrainingArguments(output_dir='SimCSE/result/my-unsup-simcse-bert-base-uncased', overwrite_output_dir=True, do_train=True, do_eval=True, do_predict=False, evaluation_strategy=<EvaluationStrategy.STEPS: 'steps'>, prediction_loss_only=False, per_device_train_batch_size=64, per_device_eval_batch_size=8, per_gpu_train_batch_size=None, per_gpu_eval_batch_size=None, gradient_accumulation_steps=1, eval_accumulation_steps=None, learning_rate=3e-05, weight_decay=0.0, adam_beta1=0.9, adam_beta2=0.999, adam_epsilon=1e-08, max_grad_norm=1.0, num_train_epochs=1.0, max_steps=-1, lr_scheduler_type=<SchedulerType.LINEAR: 'linear'>, warmup_steps=0, logging_dir='runs/Jun11_07-32-08_b24871aa421a', logging_first_step=False, logging_steps=500, save_steps=500, save_total_limit=None, no_cuda=False, seed=42, fp16=False, fp16_opt_level='O1', fp16_backend='auto', local_rank=-1, tpu_num_cores=None, tpu_metrics_debug=False, debug=False, dataloader_drop_last=False, eval_steps=125, dataloader_num_workers=0, past_index=-1, run_name='SimCSE/result/my-unsup-simcse-bert-base-uncased', disable_tqdm=False, remove_unused_columns=True, label_names=None, load_best_model_at_end=True, metric_for_best_model='stsb_spearman', greater_is_better=True, ignore_data_skip=False, sharded_ddp=False, deepspeed=None, label_smoothing_factor=0.0, adafactor=False, eval_transfer=False)\n",
            "Using custom data configuration default\n",
            "Downloading and preparing dataset text/default-2d4b3079cc46be46 (download: Unknown size, generated: Unknown size, post-processed: Unknown size, total: Unknown size) to ./data/text/default-2d4b3079cc46be46/0.0.0/daf90a707a433ac193b369c8cc1772139bb6cca21a9c7fe83bdd16aad9b9b6ab...\n",
            "Dataset text downloaded and prepared to ./data/text/default-2d4b3079cc46be46/0.0.0/daf90a707a433ac193b369c8cc1772139bb6cca21a9c7fe83bdd16aad9b9b6ab. Subsequent calls will reuse this data.\n",
            "06/11/2021 07:32:12 - INFO - filelock -   Lock 140171941372880 acquired on /root/.cache/huggingface/transformers/e0bc8d2cf8348f6e3663bba7982971d229c5d235e3d672474510049fa6bb51fd.5cd0435d169f492936af7d3ea03e91f92ece76b86fe275637c76f6db69156d86.lock\n",
            "[INFO|file_utils.py:1272] 2021-06-11 07:32:12,002 >> https://huggingface.co/princeton-nlp/unsup-simcse-bert-base-uncased/resolve/main/config.json not found in cache or force_download set to True, downloading to /root/.cache/huggingface/transformers/tmpsy7f3vrm\n",
            "Downloading: 100% 697/697 [00:00<00:00, 508kB/s]\n",
            "[INFO|file_utils.py:1276] 2021-06-11 07:32:12,247 >> storing https://huggingface.co/princeton-nlp/unsup-simcse-bert-base-uncased/resolve/main/config.json in cache at /root/.cache/huggingface/transformers/e0bc8d2cf8348f6e3663bba7982971d229c5d235e3d672474510049fa6bb51fd.5cd0435d169f492936af7d3ea03e91f92ece76b86fe275637c76f6db69156d86\n",
            "[INFO|file_utils.py:1279] 2021-06-11 07:32:12,248 >> creating metadata file for /root/.cache/huggingface/transformers/e0bc8d2cf8348f6e3663bba7982971d229c5d235e3d672474510049fa6bb51fd.5cd0435d169f492936af7d3ea03e91f92ece76b86fe275637c76f6db69156d86\n",
            "06/11/2021 07:32:12 - INFO - filelock -   Lock 140171941372880 released on /root/.cache/huggingface/transformers/e0bc8d2cf8348f6e3663bba7982971d229c5d235e3d672474510049fa6bb51fd.5cd0435d169f492936af7d3ea03e91f92ece76b86fe275637c76f6db69156d86.lock\n",
            "[INFO|configuration_utils.py:445] 2021-06-11 07:32:12,248 >> loading configuration file https://huggingface.co/princeton-nlp/unsup-simcse-bert-base-uncased/resolve/main/config.json from cache at /root/.cache/huggingface/transformers/e0bc8d2cf8348f6e3663bba7982971d229c5d235e3d672474510049fa6bb51fd.5cd0435d169f492936af7d3ea03e91f92ece76b86fe275637c76f6db69156d86\n",
            "[INFO|configuration_utils.py:481] 2021-06-11 07:32:12,249 >> Model config BertConfig {\n",
            "  \"_name_or_path\": \"result/bert-base-uncased-cls_before_pooler-sym_mlp_train_only-mlp_bert-bs64-gpu1-gs1-lr3e-5-m=stsb-norm0.05-l32-wiki\",\n",
            "  \"architectures\": [\n",
            "    \"BertModel\"\n",
            "  ],\n",
            "  \"attention_probs_dropout_prob\": 0.1,\n",
            "  \"gradient_checkpointing\": false,\n",
            "  \"hidden_act\": \"gelu\",\n",
            "  \"hidden_dropout_prob\": 0.1,\n",
            "  \"hidden_size\": 768,\n",
            "  \"initializer_range\": 0.02,\n",
            "  \"intermediate_size\": 3072,\n",
            "  \"layer_norm_eps\": 1e-12,\n",
            "  \"max_position_embeddings\": 512,\n",
            "  \"model_type\": \"bert\",\n",
            "  \"num_attention_heads\": 12,\n",
            "  \"num_hidden_layers\": 12,\n",
            "  \"pad_token_id\": 0,\n",
            "  \"position_embedding_type\": \"absolute\",\n",
            "  \"transformers_version\": \"4.2.1\",\n",
            "  \"type_vocab_size\": 2,\n",
            "  \"use_cache\": true,\n",
            "  \"vocab_size\": 30522\n",
            "}\n",
            "\n",
            "[INFO|configuration_utils.py:445] 2021-06-11 07:32:12,382 >> loading configuration file https://huggingface.co/princeton-nlp/unsup-simcse-bert-base-uncased/resolve/main/config.json from cache at /root/.cache/huggingface/transformers/e0bc8d2cf8348f6e3663bba7982971d229c5d235e3d672474510049fa6bb51fd.5cd0435d169f492936af7d3ea03e91f92ece76b86fe275637c76f6db69156d86\n",
            "[INFO|configuration_utils.py:481] 2021-06-11 07:32:12,383 >> Model config BertConfig {\n",
            "  \"_name_or_path\": \"result/bert-base-uncased-cls_before_pooler-sym_mlp_train_only-mlp_bert-bs64-gpu1-gs1-lr3e-5-m=stsb-norm0.05-l32-wiki\",\n",
            "  \"architectures\": [\n",
            "    \"BertModel\"\n",
            "  ],\n",
            "  \"attention_probs_dropout_prob\": 0.1,\n",
            "  \"gradient_checkpointing\": false,\n",
            "  \"hidden_act\": \"gelu\",\n",
            "  \"hidden_dropout_prob\": 0.1,\n",
            "  \"hidden_size\": 768,\n",
            "  \"initializer_range\": 0.02,\n",
            "  \"intermediate_size\": 3072,\n",
            "  \"layer_norm_eps\": 1e-12,\n",
            "  \"max_position_embeddings\": 512,\n",
            "  \"model_type\": \"bert\",\n",
            "  \"num_attention_heads\": 12,\n",
            "  \"num_hidden_layers\": 12,\n",
            "  \"pad_token_id\": 0,\n",
            "  \"position_embedding_type\": \"absolute\",\n",
            "  \"transformers_version\": \"4.2.1\",\n",
            "  \"type_vocab_size\": 2,\n",
            "  \"use_cache\": true,\n",
            "  \"vocab_size\": 30522\n",
            "}\n",
            "\n",
            "[INFO|tokenization_utils_base.py:1685] 2021-06-11 07:32:12,383 >> Model name 'princeton-nlp/unsup-simcse-bert-base-uncased' not found in model shortcut name list (bert-base-uncased, bert-large-uncased, bert-base-cased, bert-large-cased, bert-base-multilingual-uncased, bert-base-multilingual-cased, bert-base-chinese, bert-base-german-cased, bert-large-uncased-whole-word-masking, bert-large-cased-whole-word-masking, bert-large-uncased-whole-word-masking-finetuned-squad, bert-large-cased-whole-word-masking-finetuned-squad, bert-base-cased-finetuned-mrpc, bert-base-german-dbmdz-cased, bert-base-german-dbmdz-uncased, TurkuNLP/bert-base-finnish-cased-v1, TurkuNLP/bert-base-finnish-uncased-v1, wietsedv/bert-base-dutch-cased). Assuming 'princeton-nlp/unsup-simcse-bert-base-uncased' is a path, a model identifier, or url to a directory containing tokenizer files.\n",
            "06/11/2021 07:32:12 - INFO - filelock -   Lock 140171732275408 acquired on /root/.cache/huggingface/transformers/1c32d2a72e4e3ea18da8fa7e268fd243e6e32a64b9565095700a0a845e47fe3d.d789d64ebfe299b0e416afc4a169632f903f693095b4629a7ea271d5a0cf2c99.lock\n",
            "[INFO|file_utils.py:1272] 2021-06-11 07:32:12,519 >> https://huggingface.co/princeton-nlp/unsup-simcse-bert-base-uncased/resolve/main/vocab.txt not found in cache or force_download set to True, downloading to /root/.cache/huggingface/transformers/tmpwp11_wtm\n",
            "Downloading: 100% 232k/232k [00:00<00:00, 4.80MB/s]\n",
            "[INFO|file_utils.py:1276] 2021-06-11 07:32:12,709 >> storing https://huggingface.co/princeton-nlp/unsup-simcse-bert-base-uncased/resolve/main/vocab.txt in cache at /root/.cache/huggingface/transformers/1c32d2a72e4e3ea18da8fa7e268fd243e6e32a64b9565095700a0a845e47fe3d.d789d64ebfe299b0e416afc4a169632f903f693095b4629a7ea271d5a0cf2c99\n",
            "[INFO|file_utils.py:1279] 2021-06-11 07:32:12,709 >> creating metadata file for /root/.cache/huggingface/transformers/1c32d2a72e4e3ea18da8fa7e268fd243e6e32a64b9565095700a0a845e47fe3d.d789d64ebfe299b0e416afc4a169632f903f693095b4629a7ea271d5a0cf2c99\n",
            "06/11/2021 07:32:12 - INFO - filelock -   Lock 140171732275408 released on /root/.cache/huggingface/transformers/1c32d2a72e4e3ea18da8fa7e268fd243e6e32a64b9565095700a0a845e47fe3d.d789d64ebfe299b0e416afc4a169632f903f693095b4629a7ea271d5a0cf2c99.lock\n",
            "06/11/2021 07:32:13 - INFO - filelock -   Lock 140171733012816 acquired on /root/.cache/huggingface/transformers/94d39e4723fc8c887995cfa549a390ca9928ffb8a357d82e339d4cb6d111a886.dd8bd9bfd3664b530ea4e645105f557769387b3da9f79bdb55ed556bdd80611d.lock\n",
            "[INFO|file_utils.py:1272] 2021-06-11 07:32:13,113 >> https://huggingface.co/princeton-nlp/unsup-simcse-bert-base-uncased/resolve/main/special_tokens_map.json not found in cache or force_download set to True, downloading to /root/.cache/huggingface/transformers/tmppc6lm7jg\n",
            "Downloading: 100% 112/112 [00:00<00:00, 79.0kB/s]\n",
            "[INFO|file_utils.py:1276] 2021-06-11 07:32:13,252 >> storing https://huggingface.co/princeton-nlp/unsup-simcse-bert-base-uncased/resolve/main/special_tokens_map.json in cache at /root/.cache/huggingface/transformers/94d39e4723fc8c887995cfa549a390ca9928ffb8a357d82e339d4cb6d111a886.dd8bd9bfd3664b530ea4e645105f557769387b3da9f79bdb55ed556bdd80611d\n",
            "[INFO|file_utils.py:1279] 2021-06-11 07:32:13,252 >> creating metadata file for /root/.cache/huggingface/transformers/94d39e4723fc8c887995cfa549a390ca9928ffb8a357d82e339d4cb6d111a886.dd8bd9bfd3664b530ea4e645105f557769387b3da9f79bdb55ed556bdd80611d\n",
            "06/11/2021 07:32:13 - INFO - filelock -   Lock 140171733012816 released on /root/.cache/huggingface/transformers/94d39e4723fc8c887995cfa549a390ca9928ffb8a357d82e339d4cb6d111a886.dd8bd9bfd3664b530ea4e645105f557769387b3da9f79bdb55ed556bdd80611d.lock\n",
            "06/11/2021 07:32:13 - INFO - filelock -   Lock 140171733365328 acquired on /root/.cache/huggingface/transformers/dc1443d112dc8bfefeaacc05e9161af24a7bbae8202ffc5e4fb8ced328d767a8.8b6dccc90d16201c6d7ab0f3c6cc38e74b5f2fe587f6efadc9fa71fc0a00c606.lock\n",
            "[INFO|file_utils.py:1272] 2021-06-11 07:32:13,388 >> https://huggingface.co/princeton-nlp/unsup-simcse-bert-base-uncased/resolve/main/tokenizer_config.json not found in cache or force_download set to True, downloading to /root/.cache/huggingface/transformers/tmpkpxnqnw8\n",
            "Downloading: 100% 252/252 [00:00<00:00, 184kB/s]\n",
            "[INFO|file_utils.py:1276] 2021-06-11 07:32:13,524 >> storing https://huggingface.co/princeton-nlp/unsup-simcse-bert-base-uncased/resolve/main/tokenizer_config.json in cache at /root/.cache/huggingface/transformers/dc1443d112dc8bfefeaacc05e9161af24a7bbae8202ffc5e4fb8ced328d767a8.8b6dccc90d16201c6d7ab0f3c6cc38e74b5f2fe587f6efadc9fa71fc0a00c606\n",
            "[INFO|file_utils.py:1279] 2021-06-11 07:32:13,524 >> creating metadata file for /root/.cache/huggingface/transformers/dc1443d112dc8bfefeaacc05e9161af24a7bbae8202ffc5e4fb8ced328d767a8.8b6dccc90d16201c6d7ab0f3c6cc38e74b5f2fe587f6efadc9fa71fc0a00c606\n",
            "06/11/2021 07:32:13 - INFO - filelock -   Lock 140171733365328 released on /root/.cache/huggingface/transformers/dc1443d112dc8bfefeaacc05e9161af24a7bbae8202ffc5e4fb8ced328d767a8.8b6dccc90d16201c6d7ab0f3c6cc38e74b5f2fe587f6efadc9fa71fc0a00c606.lock\n",
            "[INFO|tokenization_utils_base.py:1766] 2021-06-11 07:32:13,525 >> loading file https://huggingface.co/princeton-nlp/unsup-simcse-bert-base-uncased/resolve/main/vocab.txt from cache at /root/.cache/huggingface/transformers/1c32d2a72e4e3ea18da8fa7e268fd243e6e32a64b9565095700a0a845e47fe3d.d789d64ebfe299b0e416afc4a169632f903f693095b4629a7ea271d5a0cf2c99\n",
            "[INFO|tokenization_utils_base.py:1766] 2021-06-11 07:32:13,525 >> loading file https://huggingface.co/princeton-nlp/unsup-simcse-bert-base-uncased/resolve/main/tokenizer.json from cache at None\n",
            "[INFO|tokenization_utils_base.py:1766] 2021-06-11 07:32:13,525 >> loading file https://huggingface.co/princeton-nlp/unsup-simcse-bert-base-uncased/resolve/main/added_tokens.json from cache at None\n",
            "[INFO|tokenization_utils_base.py:1766] 2021-06-11 07:32:13,525 >> loading file https://huggingface.co/princeton-nlp/unsup-simcse-bert-base-uncased/resolve/main/special_tokens_map.json from cache at /root/.cache/huggingface/transformers/94d39e4723fc8c887995cfa549a390ca9928ffb8a357d82e339d4cb6d111a886.dd8bd9bfd3664b530ea4e645105f557769387b3da9f79bdb55ed556bdd80611d\n",
            "[INFO|tokenization_utils_base.py:1766] 2021-06-11 07:32:13,525 >> loading file https://huggingface.co/princeton-nlp/unsup-simcse-bert-base-uncased/resolve/main/tokenizer_config.json from cache at /root/.cache/huggingface/transformers/dc1443d112dc8bfefeaacc05e9161af24a7bbae8202ffc5e4fb8ced328d767a8.8b6dccc90d16201c6d7ab0f3c6cc38e74b5f2fe587f6efadc9fa71fc0a00c606\n",
            "06/11/2021 07:32:13 - INFO - filelock -   Lock 140171941372880 acquired on /root/.cache/huggingface/transformers/32e195629d15066803abaedba6f0e321abc8b76cabef006e697fb096d726f989.6916dc4eb41e5dfbef6cc821fad81b39f215995a3c7ca2d0bf1879ced5a5125b.lock\n",
            "[INFO|file_utils.py:1272] 2021-06-11 07:32:13,711 >> https://huggingface.co/princeton-nlp/unsup-simcse-bert-base-uncased/resolve/main/pytorch_model.bin not found in cache or force_download set to True, downloading to /root/.cache/huggingface/transformers/tmpib320d3g\n",
            "Downloading: 100% 438M/438M [00:09<00:00, 44.5MB/s]\n",
            "[INFO|file_utils.py:1276] 2021-06-11 07:32:23,757 >> storing https://huggingface.co/princeton-nlp/unsup-simcse-bert-base-uncased/resolve/main/pytorch_model.bin in cache at /root/.cache/huggingface/transformers/32e195629d15066803abaedba6f0e321abc8b76cabef006e697fb096d726f989.6916dc4eb41e5dfbef6cc821fad81b39f215995a3c7ca2d0bf1879ced5a5125b\n",
            "[INFO|file_utils.py:1279] 2021-06-11 07:32:23,757 >> creating metadata file for /root/.cache/huggingface/transformers/32e195629d15066803abaedba6f0e321abc8b76cabef006e697fb096d726f989.6916dc4eb41e5dfbef6cc821fad81b39f215995a3c7ca2d0bf1879ced5a5125b\n",
            "06/11/2021 07:32:23 - INFO - filelock -   Lock 140171941372880 released on /root/.cache/huggingface/transformers/32e195629d15066803abaedba6f0e321abc8b76cabef006e697fb096d726f989.6916dc4eb41e5dfbef6cc821fad81b39f215995a3c7ca2d0bf1879ced5a5125b.lock\n",
            "[INFO|modeling_utils.py:1027] 2021-06-11 07:32:23,757 >> loading weights file https://huggingface.co/princeton-nlp/unsup-simcse-bert-base-uncased/resolve/main/pytorch_model.bin from cache at /root/.cache/huggingface/transformers/32e195629d15066803abaedba6f0e321abc8b76cabef006e697fb096d726f989.6916dc4eb41e5dfbef6cc821fad81b39f215995a3c7ca2d0bf1879ced5a5125b\n",
            "[INFO|modeling_utils.py:1143] 2021-06-11 07:32:28,250 >> All model checkpoint weights were used when initializing BertForCL.\n",
            "\n",
            "[WARNING|modeling_utils.py:1146] 2021-06-11 07:32:28,250 >> Some weights of BertForCL were not initialized from the model checkpoint at princeton-nlp/unsup-simcse-bert-base-uncased and are newly initialized: ['mlp.dense.bias', 'mlp.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "100% 1001/1001 [03:15<00:00,  5.13ba/s]\n",
            "[INFO|trainer.py:442] 2021-06-11 07:35:43,466 >> The following columns in the training set don't have a corresponding argument in `BertForCL.forward` and have been ignored: .\n",
            "06/11/2021 07:35:43 - INFO - simcse.trainers -   ***** Running training *****\n",
            "06/11/2021 07:35:43 - INFO - simcse.trainers -     Num examples = 1000001\n",
            "06/11/2021 07:35:43 - INFO - simcse.trainers -     Num Epochs = 1\n",
            "06/11/2021 07:35:43 - INFO - simcse.trainers -     Instantaneous batch size per device = 64\n",
            "06/11/2021 07:35:43 - INFO - simcse.trainers -     Total train batch size (w. parallel, distributed & accumulation) = 64\n",
            "06/11/2021 07:35:43 - INFO - simcse.trainers -     Gradient Accumulation steps = 1\n",
            "06/11/2021 07:35:43 - INFO - simcse.trainers -     Total optimization steps = 15626\n",
            "{'eval_stsb_spearman': 0.7143272883385511, 'eval_sickr_spearman': 0.6807897577933167, 'eval_avg_sts': 0.6975585230659339, 'epoch': 0.01}\n",
            "  1% 125/15626 [2:08:03<166:04:00, 38.57s/it][INFO|trainer.py:1344] 2021-06-11 09:43:46,618 >> Saving model checkpoint to SimCSE/result/my-unsup-simcse-bert-base-uncased\n",
            "[INFO|configuration_utils.py:300] 2021-06-11 09:43:46,628 >> Configuration saved in SimCSE/result/my-unsup-simcse-bert-base-uncased/config.json\n",
            "[INFO|modeling_utils.py:817] 2021-06-11 09:43:48,656 >> Model weights saved in SimCSE/result/my-unsup-simcse-bert-base-uncased/pytorch_model.bin\n",
            "  1% 153/15626 [2:26:08<164:12:55, 38.21s/it]"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 129
        },
        "id": "MmWFEuGNSdL0",
        "outputId": "0c67ce63-003e-4a80-c1d1-0ac42730ad61"
      },
      "source": [
        "!python /content/SimCSE/train.py \\\n",
        "    --model_name_or_path princeton-nlp/unsup-simcse-bert-base-uncased \\\n",
        "    --temp 0.05 \\\n",
        "    --train_file /content/wiki1m_for_simcse.txt \\\n",
        "    --pooler cls_before_pooler \\\n",
        "    --task_set sts \\\n",
        "    --num_train_epochs 1 \\\n",
        "    --per_device_train_batch_size 64 \\\n",
        "    --learning_rate 3e-5 \\\n",
        "    --max_seq_length 32 \\\n",
        "    --evaluation_strategy steps \\\n",
        "    --metric_for_best_model stsb_spearman \\\n",
        "    --load_best_model_at_end \\\n",
        "    --eval_steps 125 \\ \n",
        "    --do_train \\\n",
        "    --do_eval "
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "IndentationError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;36m  File \u001b[0;32m\"<ipython-input-7-3a730fdec195>\"\u001b[0;36m, line \u001b[0;32m2\u001b[0m\n\u001b[0;31m    --do_train     --do_eval\u001b[0m\n\u001b[0m    ^\u001b[0m\n\u001b[0;31mIndentationError\u001b[0m\u001b[0;31m:\u001b[0m unexpected indent\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4JBpuB-pBxxS"
      },
      "source": [
        "!python /content/SimCSE/simcse_to_huggingface.py --path /content/checkpoints/"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rtQrDAGNdHG4"
      },
      "source": [
        "!python /content/SimCSE/evaluation.py \\\n",
        "    --model_name_or_path princeton-nlp/unsup-simcse-bert-base-uncased \\\n",
        "    --pooler cls_before_pooler \\\n",
        "    --task_set sts \\\n",
        "    --mode test"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}